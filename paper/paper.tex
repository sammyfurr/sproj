\documentclass[12pt]{article}
\usepackage{multicol}
\usepackage{cite}

\usepackage{graphicx}
\usepackage[doublespacing]{setspace}
\usepackage{hyperref}
\usepackage{titlesec}
\newcommand{\sectionbreak}{\clearpage}

\usepackage[dvipsnames]{xcolor}
\usepackage{listingsutf8}

% From: https://gordonlesti.com/custom-code-highlighting-in-latex/

\lstdefinelanguage{Dockerfile}
{
  morekeywords={FROM, RUN, CMD, LABEL, MAINTAINER, EXPOSE, ENV, ADD, COPY,
    ENTRYPOINT, VOLUME, USER, WORKDIR, ARG, ONBUILD, STOPSIGNAL, HEALTHCHECK,
    SHELL},
  morecomment=[l]{\#},
  morestring=[b]"
}


\newcommand\YAMLcolonstyle{\color{red}\mdseries}
\newcommand\YAMLkeystyle{\color{black}\bfseries}
\newcommand\YAMLvaluestyle{\color{blue}\mdseries}

% From: https://tex.stackexchange.com/questions/152829/how-can-i-highlight-yaml-code-in-a-pretty-way-with-listings

\makeatletter

% here is a macro expanding to the name of the language
% (handy if you decide to change it further down the road)
\newcommand\language@yaml{yaml}

\expandafter\expandafter\expandafter\lstdefinelanguage
\expandafter{\language@yaml}
{
  keywords={true,false,null,y,n},
  keywordstyle=\color{darkgray}\bfseries,
  basicstyle=\YAMLkeystyle,                                 % assuming a key comes first
  sensitive=false,
  comment=[l]{\#},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\YAMLvaluestyle\ttfamily,
  moredelim=[l][\color{orange}]{\&},
  moredelim=[l][\color{magenta}]{*},
  moredelim=**[il][\YAMLcolonstyle{:}\YAMLvaluestyle]{:},   % switch to value style at :
  morestring=[b]',
  morestring=[b]",
  literate =    {---}{{\ProcessThreeDashes}}3
                {>}{{\textcolor{red}\textgreater}}1     
                {|}{{\textcolor{red}\textbar}}1 
                {\ -\ }{{\mdseries\ -\ }}3,
}

% switch to key style at EOL
\lst@AddToHook{EveryLine}{\ifx\lst@language\language@yaml\YAMLkeystyle\fi}
\makeatother

\newcommand\ProcessThreeDashes{\llap{\color{cyan}\mdseries-{-}-}}

\lstset{basicstyle=\linespread{0.5}\ttfamily,
  showstringspaces=false,
  commentstyle=\color{red},
  keywordstyle=\color{blue},
  inputencoding=utf8,
  extendedchars=true
}

\graphicspath{{./images/}}

\author{Sammy Furr}
\title{The Development of a Collaborative Tool to Teach Debugging}
\date{\today}

\begin{document}

\begin{titlepage}
  \maketitle
\end{titlepage}

\begin{abstract}
  TODO: write an abstract
\end{abstract}

\tableofcontents
\pagebreak

\section{Introduction}
\subsection{Motivation}

Debugging is invaluable in writing and understanding code, yet it is
rarely formally taught\cite{doi:10.1080/08993400802114581}.  We
typically teach students programming structures, concepts, and
languages, but leave them to learn the tools they use to write code by
themselves.  This approach often works well---a programmer's choice of
tools is often \textit{very} personal and students figure out how to
configure an individualized workflow.  Perhaps because debuggers are
tools, students are often expected to learn them with minimal
guidance.  Unlike editors or reference guides however, effectively
using a debugger requires a set of high-level, platform agnostic,
teachable skills.  Teaching these skills is effective, and translates
into better, faster, debugging and
programming\cite{10.1145/3286960.3286970}\cite{10.1145/3361721.3361724}.

\subsubsection{The Value of Teaching Debugging}

There is an unfortunate lack of research specifically into the
efficacy of teaching debugging for computer science students, despite
a recent rise in the inclusion of debugging in ``computational
thinking'' curriculums\cite{10.1145/3361721.3361724}.  These
curriculums attempt to teach skills in computer science classes that
translate into other subject areas: the UK's computer science
curriculum considers debugging an essential ``transferable
skill''\cite{10.1145/2602484}.\par There seems to be confidence that
the problem-solving techniques used in debugging are widely
applicable, but of greater interest to computer science teachers is
whether teaching debugging directly benefits student programmers.
Michaeli and Romeike conducted a good, albeit somewhat small, study on
the efficacy of teaching a systematic debugging process to K12
students.  They found that students who have been taught a specific
debugging framework performed better in debugging tests and were more
confident in their own debugging skills\cite{10.1145/3361721.3361724}.
Their result is positive evidence towards the efficacy of teaching
debugging, though it doesn't include college or university
students.\par

As Michaeli and Romeike point out, there is a lack of research into
the value of teaching debugging in higher education.  None of the
research these authors found placed much focus on explicitly teaching
debugging.  Chmiel and Loui studied whether students who were provided
with debugging tools and frameworks performed better on tests or spent
less time on assignments than those who were
not\cite{10.1145/971300.971310}.  Though this research wasn't able to
find conclusive evidence towards better performance on tests or
assignments, it did find that students in the treatment group felt
more confident in their debugging abilities.  Unfortunately Chmiel and
Loui's study didn't involve extended explicit teaching of
debugging---use of the tools was voluntary, and variations in the
students' individual abilities made the data difficult to
evaluate.\par

Though there is a lack of higher-education research, the value of
teaching debugging is still demonstrable.  The research discussed all
finds that K-12 and college students alike commonly resort to sporadic
debugging techniques when beginning to learn.  Since this pattern of
behavior that explicitly teaching debugging corrects exists in college
as well as in K-12 students, it seems logical that the benefit of
explicitly teaching debugging to K-12 students should be realized
equally by their collegiate counterparts.\par

\subsubsection{Methods for Teaching Debugging}

Similarly to research on the value of teaching debugging, research
into how to best teach debugging is self-admittedly sparse.  Chan et
al. allow that ``in general research on how to improve debugging is
sporadic''---an observation that leads them to research a framework to
reduce the complexity of teaching
debugging\cite{10.1145/3286960.3286970}.  To organize their framework,
they split debugging knowledge into 5 categories: \textit{Domain},
\textit{System}, \textit{Procedural}, \textit{Strategic}, and
\textit{Experiential}.  They then review different debugging tools and
teaching aids---from those that involve writing code to games---and
map tools to the knowledge areas they seek to address.  After an
evaluation of a host of different tools, they claim to find a few
significant faults in current debugging teaching platforms. The
primary two which this project seeks to address are as follows:

\begin{enumerate}
\item A lack of back-tracing ability/coverage.
\item A lack of tools addressing system knowledge (an understanding of
  the program to be debugged).
\end{enumerate}

\subsubsection{The Value of Collaborative Programming}

TODO: find some basic research that backs up the claim that
collaborative/pair programming is worthwhile.

\subsubsection{Tools that Enable Collaborative Programming}

TODO: write about glitch, repl.it, etc.

\subsubsection{Collaborative Programming and Teaching Debugging}

Debuggers exist at an intersection of tools and skills similar to
programming languages themselves. By becoming familiar with a specific
debugger, students learn techniques and paradigms necessary to use all
debuggers effectively.
\pagebreak

\subsection{Tools Used}

\begin{figure}[h!]

  \includegraphics[scale=.8]{overall_system}
  \centering
  \caption{Overview of the Collaborative Debugger}
  \label{debugger:overview}
\end{figure}

The next sections give an overview of the various tools used to create
the collaborative debugger.  The debugger consists of:

\begin{enumerate}
\item A frontend web app built using React (\ref{react}) that presents a debugging
  interface to the end user.
\item A distributed backend managed by Kubernetes (\ref{k8s}), split into three parts:
  \begin{enumerate}
  \item A Pod for each debugging instance which runs the rr debugger
    (\ref{rr}).  These communicate directly with users through
    WebSocket server Pods. (\ref{socketio}).
  \item Pods running a frontend server written in Node.js which works
    in tandem with an API server created using Flask
    (\ref{flask/node}).  The API server manages creation and
    destruction of debug sessions, as well as authentication.
  \item A MongoDB (\ref{mongodb}) database.
  \end{enumerate}
\end{enumerate}

\subsubsection{Kubernetes}\label{k8s}

Kubernetes is the defacto standard in container orchestration
software.  It provides a layer of abstraction on top of normal
containers, like those created by Docker.  By bundling one or more
closely linked containers into a ``Pod'', Kubernetes is able to manage
deployment and re-deployment of applications running inside
containers.  It is trivial to create new Pods, or to create multiple
Pods running the same application as needed within a Kubernetes
cluster \cite{k8s}.  The speed at which even relatively large Pods can be created
and the inherent security provided by containerization drove the
decision to create a new Pod on the fly for each debugging instance in
the collaborative debugger.
\par

Kubernetes also provides services to facilitate load balancing, manage
storage volumes, and contain secrets.  The abstraction provided by
these features, in tandem with the ease of Kubernetes deployment on a
managed Kubernetes service\cite{do_managed_k8s} greatly accelerated
development.

\subsubsection{Mozilla's rr}\label{rr}

\paragraph{Overview}

rr is ``a lightweight tool for recording, replaying and debugging
execution of applications''\cite{rr-repo}. rr allows a programmer to
record the execution of a program on any compatible machine and replay
the execution later.  This enhances GDB's ability to ``time-travel''
when debugging, using commands such as \lstinline{reverse-continue}
and \lstinline{reverse-stepi}\cite{gdbman} to step backwards and
forwards through a program's execution.  Through a novel encapsulation
of the execution space, rr is able to deterministically record and
replay the execution of syscalls and other process behavior that
differs run-to-run.  This is invaluable when trying to debug behavior
that is not entirely dependent on the code being debugged.  A typical
workflow in rr consists of recording an inexplicable error, replaying
execution to find the area in which the error occurs, and then
narrowing in on the bug not by re-running the entire program, but by
progressing back and forth through execution in the problem area.
\par

rr is an ideal tool for teaching debugging because it allows
instructors to record execution of a program and design a debugging
example with the knowledge that normally non-deterministic events will
be repeatable, and that any input they provide to the program will be
exactly replicated.  With the collaborative debugger, teachers can
record a program's execution and design a debugging lesson which
students can work on together.  The repeatability of rr means that
students can focus on debugging, and teachers can create as specific
examples as they please.

\paragraph{Limitations}

In comparison to solutions like PANDA\cite{10.1145/2843859.2843867}
that rely on capturing the entire state of of a virtual machine to
replay execution, rr records and replays faster, produces far smaller
files, and doesn't force execution inside of a
VM.\cite{DBLP:journals/corr/OCallahanJFHNP17} The trade off for these
benefits are two major system limitations: rr is only compatible with
the Linux kernel, and it's deterministic recording and replay relies
on a feature that is only found on modern \textit{Intel} x86 CPUs.
These limitations influenced the development of this project as a
webapp similar to existing tools for collaborative programming.
\par

Luckily, the speed and size benefits of rr lend themselves well to
non-local execution.  In conjunction with Kubernetes, it takes a few
seconds to create a new container running rr and connect to web
clients.

\subsubsection{pygdbmi}

In order to ``support the development of systems which use the
debugger as just one small component of a larger system'', GDB
provides a machine-oriented interface called GDB/MI \cite{gdbman}. rr
supports interaction through GDB/MI, and using the interface was a
natural choice for the collaborative debugger.  In addition to being
far easier to interact with from within a program, the structured,
machine-friendly output of GDB/MI lends itself in particular to future
development of visualization aids in the collaborative debugger.
\par
To parse rr output into Python dictionaries and to easily control rr
as a subprocess, pygdbmi \cite{pygdbmi} is used in each debugging Pod.
pygdbmi's abstraction simplifies programatically controlling rr.  A
Pod can receive a command from the client, pass it to rr, and respond
without having to deal with parsing GDB/MI output or managing the rr
process.

\subsubsection{Socket.IO}\label{socketio}

To speed communication, the collaborative debugger uses WebSockets to
directly connect web clients and the Pods running rr.  Socket.IO is a
library that extends WebSockets.  It provides backup incase a
WebSocket connection cannot be established, enables automatic
reconnection and disconnection detection, and adds support for
namespaces \cite{socketio}.  The collaborative debugger uses the
standard JavaScript implementation of Socket.IO on the client side.
Messages are passed through a server to individual debugging Pods,
both of which use the Python implementation of Socket.IO,
python-socket.io \cite{python_socketio}.

\subsubsection{MongoDB}\label{mongodb}

The collaborative debugger uses a database to store information about
users, Pods, and example debugging sessions.  Due to it's speed of
deployment and natural interaction with the object-oriented languages
used to create the project, MongoDB was chosen as database software
\cite{mongodb}.

\subsubsection{Flask and Node.js}\label{flask/node}

The primary server for the collaborative debugger is split into two
sections: a simple Node.js \cite{node} server that serves the frontend
webapp, and an API server created using Flask \cite{flask}.  While in
development, the builtin React (see next section) development server
is used to serve the frontend.  This makes debugging the frontend far
easier.
\par

An API server is necessary to authenticate users and to provide a
means to create/delete debugging sessions.  Since the rest of the
backend was created using Python, Flask was chosen to create the API
server.  Flask is a lightweight web application framework which lends
itself perfectly to interacting with the Python MongoDB and Kubernetes
APIs.

\subsubsection{React}\label{react}

React is JavaScript library that simplifies creating user interfaces
and managing state \cite{react}.  React's state management is of
particular importance to the collaborative debugger's frontend.  State
constantly changes as users create/delete debugging sessions, join
existing sessions, and communicate with rr.  React allows classes to
encapsulate components such as a list of existing debugging sessions,
a view of the current program's source code, and the terminal
interface with rr.  Instances of these classes maintain state
and update efficiently.
\par
The frontend makes extensive use of JSX, syntax which allows the
inclusion of segments of HTML code within a React app written in
JavaScript.  This makes it easy for each component of the one-page
webapp to hide/show subcomponents as state changes.

\subsubsection{Monaco and Xterm.js}\label{xtermjs/monaco}

After joining or creating a debugging session, users spend most of
their time interacting collaboratively with rr.  Their primary
interface to rr is through Xterm.js, a frontend component that makes
it easy to emulate terminal behavior in the browser \cite{xtermjs}.
With a few control methods, it is simple to provide a terminal
interface to rr that is virtually indistinguishable from a local
session.  By using the Xterm.js based interface, students can learn to
use rr (and by extension gdb) collaboratively, and directly translate
that knowledge to individual work.
\par

In addition to the terminal interface, the frontend shows a view of
the current source file being debugged.  The Monaco Editor
\cite{monaco} is used to display this source view.  Though more
complex than is strictly necessary to display code, Monaco makes it
easy to format and syntax-highlight.  Using Monaco also simplifies the
future addition of editing source code, should the need arise.
React's state management allows updating text in the editor as
efficiently as possible.

\section{Design}

The collaborative debugger consists of a distributed Kubernetes
backend and frontend React webapp.  Kubernetes was chosen for the
backend primarally so that a Pod could be created dynamically for each
debugging session.  The design of the backend is heavily distributed,
allowing individual components to be modified without the whole system
needing to be reconfigured.

\begin{figure}[h!]

  \includegraphics[scale=.9]{detailed_system}
  \centering
  \caption{Detailed Overview of the Collaborative Debugger}
  \label{debugger:detailedoverview}
\end{figure}

Each backend component of the collaborative debugger runs in it's own
individual Pod.  There are two different classes of Pods in the
collaborative debugger:

\begin{enumerate}
\item Statically created Pods.  These are the \textit{RR Message
    Server Pods}, the \textit{Frontend/API Server Pods}, and the
  \textit{Database Pod}.  This class of Pods are manually created when
  the cluster that will run the backend is first initialized.  The RR
  Message Server Pods and Frontend/API Server Pods may be created
  using Deployments \cite{k8s_docs} to allow later scaling, where
  multiple Pods running the same application may be created to
  facilitate increased load.
\item Dynamically created Pods.  This class of Pod contains the
  individual instances of \textit{RR Debug Pods} that are created on
  request by the API server.  When a client requests a new debug
  session, the API server uses the Kubernetes API to create a new Pod
  based on an existing template, gives the Pod a unique identifier,
  and associates it in the database with the requesting client.
\end{enumerate}

These Pods communicate with other Pods in the cluster and with the
outside world through Services.  The Kubernetes documentation defines
a Service as ``an abstraction which defines a logical set of Pods and
a policy by which to access them'' \cite{k8s_docs}.  In the
collaborative debugger, these Services manifest as:

\begin{enumerate}
\item The \textit{Database ClusterIP}: a ClusterIP, which exposes the
  Database Pod only inside the cluster.  The only component that makes
  use of this ClusterIP is the API server, which uses it primarily to
  communicate information about users and RR Debug Pods with the
  database.
\item The \textit{RR Message Load Balancer}: a Load Balancer, which
  exposes the RR Message Server Pods to the outside world.  Using
  Socket.IO, clients send commands to and recieve responses from
  individual RR Debug Pods through the RR Message Server Pods.
\item The \textit{Frontend Load Balancer}: another Load Balancer,
  which exposes the Frontend/API Server Pods to the outside world.
  Clients request the frontend webapp and send api requests/recieve
  api responses through this Load Balancer.
\end{enumerate}

The frontend webapp dynamically updates as the user requests new debug
sessions, issues commands to rr, and visits new source files.  A user
can be part of multiple debug sessions simultaneously.  Each debug
session is assigned at 5 digit identifier at creation, which is used
to join sessions in progress.
\par

Each component of the backend and
frontend will be discussed in depth in the following sections.

\subsection{Configuration and Setup}

Configuration and setup of the collaborative debugger is relatively
simple.  After a Kubernetes cluster is created (this is made easier by
using a Managed Kubernetes service) Pods and Services are created
using various configuration files.  Services should be created first,
so that Pods can be created which rely on access to Services in order
to run.  The following sections outline the process of creating a
cluster, Pods, and Services, with a focus on statically created Pods.
The process of building images for building dynamically created Pods
is identical, but the process of starting the Pods is more
complicated.  This process will be discussed in-depth in the section
on the API server \ref{api}.

\subsubsection{Cluster Selection and Configuration}

Though Docker and by extension Kubernetes aim to be largely
platform-agnostic, the requirements of rr impose some restrictions on
cluster setup and configuration.  Clusters, even those running inside
a VM, must be run on machines using relatively modern Intel x86 CPUs
(Nehalem and beyond).  The clusters must run on an operating system
using Linux kernel version 3.11 or higher \cite{rr-repo}.  The reasons
for these restrictions are discussed in the section on rr (\ref{rr}).
Finally, in order for rr to be able to work efficiently, the
\lstinline{kernel.perf_event_paranoid} parameter must be set to 1
\cite{rr-repo}.  This should be done on every node in the cluster
which will run RR Debug Pods.  For the purposes of development, it has
been set to 1 on all nodes in the collaborative debugger cluster.

\subsubsection{Creating Pods}

\begin{figure}[h!]

  \includegraphics[scale=.9]{pod_creation}
  \centering
  \caption{The Pod Creation Process}
  \label{podcreation:overview}
\end{figure}

Pods are created in five steps:

\begin{enumerate}
\item A \lstinline{Dockerfile} is used to build a new Docker container
  image from various pieces of source code, scripts, and a base image
  (such as the official MongoDB image or official Ubuntu image).  The
  Dockerfile also contains instructions to install necessary packages,
  run build scripts, and create file structures in the image.
\item The Docker image is tagged and uploaded to a private container
  registry.
\item A Pod configuration schema is defined/updated with details of
  the corresponding image's tag and any necessary Pod-specific
  settings/startup commands.
\item The Pod configuration schema is applied, either statically or
  dynamically.  When the schema is applied, Kubernetes pulls the image
  from the container registry and creates a new Pod according to the
  schema, running any startup commands if provided.
\item If Pod creation is successful, the result is a new Pod running
  in the cluster.
\end{enumerate}

\paragraph{1. Docker Container Creation}

Docker containers are created using a Dockerfile.  The Dockerfile used
to create the container image for the RR Message
Server is shown below.\\

\begin{lstlisting}[language=Dockerfile,caption={RR Message Server Dockerfile},captionpos=b]
# Base Image
FROM  ubuntu:latest

# Package Installation
WORKDIR /tmp/
ENV DEBIAN_FRONTEND="noninteractive"
RUN apt-get update && apt-get install -y \
python3-pexpect python3-pip

# User Creation
RUN useradd -ms /bin/bash rrserver
USER rrserver

# File structure creation/app setup
RUN pip3 install requests python-socketio \
eventlet
WORKDIR /home/rrserver/
RUN mkdir app
WORKDIR /home/rrserver/app/
COPY server.py .
COPY startup.sh .

# Startup command
CMD ["sh", "startup.sh"]
\end{lstlisting}

The build process for each collaborative debugger Docker image follows
the same structure as the one outlined in the Dockerfile above:

\begin{enumerate}
\item The base image is defined. The RR Message Server and RR Debug
Pod images are based on the latest Ubuntu image.  This is particuarly
necessary for the RR Debug Pod image, as rr's low-level nature
facilitates frequent updates as changes are made to the Linux kernel.
The Frontend/API Server image is based on the latest Node image, and
the Database image is based on the latest MongoDB image.
\item Second, any necessary packages are installed.  For the RR Debug
  Pod image, rr is compiled from source and installed.
\item A non-root user is created if necessary.
\item Program files are copied over and a file structure is created.
  Packages that don't rely on the base images builtin package manager
  are installed here.
\item A startup command is defined.
\end{enumerate}

Each line in a Dockerfile corresponds to a layer in the built image.
This build order minimizes the amount of rebuilding necessary by
placing the items that are most likely to change towards the end of
the build process.

\paragraph{2. Container Registry Upload}

Most Managed Kubernetes services come with the option to create a
private container registry.  With proper authentication, this allows
Docker and Kubernetes to access user-created images as easily as if
they were in a public registry.  Images built with Docker are uploaded
to a private container registry for use in the collaborative debugger.

\paragraph{3. Pod Configuration Schema}

The Pod configuration schema for most Pods in the collaborative
debugger is fairly generic.  It consists of a \lstinline{name}, an
\lstinline{image} sourced from the container registry, and in the case
of pods that need to interact with a load balancer, an
\lstinline{app}.

\begin{lstlisting}[language=YAML,basicstyle=\linespread{0.5}\ttfamily,caption={RR Debug Pod Schema},captionpos=b]
apiVersion: v1
kind: Pod
metadata:
  name: rr-translation
  labels:
    purpose: translate-rr
spec:
  containers:
  - name: rr-test-container
    image: # Redacted
    securityContext:
      capabilities:
        add:
        - SYS_PTRACE
  restartPolicy: OnFailure
\end{lstlisting}

A notable exception is the RR Debug Pod Schema, which adds the
\lstinline{SYS_PTRACE} capability to the Pod.  This is necessary for
rr to properly trace system calls.

\paragraph{4 \& 5. Pod Creation}

For statically created Pods, the \lstinline{kubectl apply} command is
used to create new Pods.  Kubernetes pulls the container image defined
in the schema from the container registry and starts the Pod with any
necessary commands.  The database Pod is connected to a long-term
storage volume at this time.  Upon successful creation, the Pod is
ready to interact with any necessary load balancers.

\subsection{Frontend/API Server}\label{api}

We just need this in here for the ref for now. TODO.

\section{Next Steps}

TODO

\pagebreak
\bibliographystyle{acm}
\bibliography{sprojbib}{}
\end{document}
